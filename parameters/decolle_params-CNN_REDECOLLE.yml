Nhid: 
- 16
- 32
- 64
Mhid: 
-  200
alpha:
- 0.92833
alpharp:
- 0.85
batch_size: 72
beta:
- 0.85
betas:
- 0.
- 0.95
burnin_steps: 25
chunk_size_test: 50 #1800
chunk_size_train: 125 #500
dataset: 
deltat: 1000
input_shape:
- 2
- 32
- 16
kernel_size:
- 5
- 5
- 5
- 1
pool_size:
- 2
- 2
- 2
- 1
lc_ampl: 
learning_method: 'bptt'
loss: smoothL1
loss_scope: 'bptt'
lr_drop_factor: 2
lr_drop_interval: 30
num_epochs: 1000
num_conv_layers: 3
num_mlp_layers: 1
num_layers: 1
num_dl_workers: 3
optimizer: adamax
out_channels: 5
online_update: False
act_rate: 0.288
dropout:
- 0
random_tau: false
reg_l:
- .0
stride:
test_interval: 1
wrp: 1.
