Nhid: []
Mhid: 
-  128
-  128
-  128
alpha:
- 0.92833
alpharp:
- 0.85
batch_size: 72
beta:
- 0.85
betas:
- 0.
- 0.95
burnin_steps: 70
chunk_size_test: 100 #1800
chunk_size_train: 100 #500
dataset: 
deltat: 1000
input_shape:
- 2
- 32
- 16
kernel_size:
lc_ampl: 0.5
learning_rate: 1.e-2
learning_method: 'bptt'
loss: smoothL1
loss_scope: 'bptt'
lr_drop_factor: 2
lr_drop_interval: 30
num_epochs: 1000
num_conv_layers: 0
num_mlp_layers: 3
num_layers: 3
num_dl_workers: 3
optimizer: adamax
out_channels: 5
online_update: False
act_rate: 0.288
pool_size:
dropout:
- 0
random_tau: false
reg_l:
- .0
stride:
test_interval: 1
wrp: 1.
